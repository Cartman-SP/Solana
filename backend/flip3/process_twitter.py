import asyncio
import aiohttp
import os
import sys
import django
import re
from typing import Optional, List
import time

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from asgiref.sync import sync_to_async
from mainapp.models import Token

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
MAX_CONCURRENT_REQUESTS = 15
REQUEST_DELAY = 1  # 100ms –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
IPFS_GATEWAY = "http://205.172.58.34/ipfs/"
IRYS_NODES = [
    "https://node1.irys.xyz/",
    "https://node2.irys.xyz/"
]

class TokenProcessor:
    def __init__(self):
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=10),
            connector=aiohttp.TCPConnector(limit=MAX_CONCURRENT_REQUESTS)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_tokens_batch(self, limit: int = 20) -> List[Token]:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∞—Ç—á —Ç–æ–∫–µ–Ω–æ–≤ —Å twitter_got = False"""
        tokens = await sync_to_async(list)(
            Token.objects.filter(twitter_got=False)[:limit]
        )
        return tokens
    
    def extract_ipfs_hash(self, uri: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å IPFS —Ö–µ—à –∏–∑ URI"""
        ipfs_patterns = [
            r'https://ipfs\.io/ipfs/([a-zA-Z0-9]+)',
            r'https://gateway\.pinata\.cloud/ipfs/([a-zA-Z0-9]+)'
        ]
        
        for pattern in ipfs_patterns:
            match = re.search(pattern, uri)
            if match:
                return match.group(1)
        return None
    
    def is_irys_uri(self, uri: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URI Irys —Å—Å—ã–ª–∫–æ–π"""
        return 'irys' in uri.lower()
    
    async def fetch_metadata(self, url: str, description: str = "") -> Optional[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –Ω–∞–≥—Ä—É–∑–∫–∏"""
        async with self.semaphore:
            try:
                print(f"–ó–∞–ø—Ä–æ—Å –∫ {description}: {url}")
                async with self.session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç {description}")
                        return data
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞ {response.status} –æ—Ç {description}")
                        return None
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {description}: {e}")
                return None
            finally:
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–¥–æ—Å–∞
                await asyncio.sleep(REQUEST_DELAY)
    
    async def process_ipfs_uri(self, uri: str) -> Optional[dict]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å IPFS URI —á–µ—Ä–µ–∑ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π —à–ª—é–∑"""
        ipfs_hash = self.extract_ipfs_hash(uri)
        if not ipfs_hash:
            return None
        
        gateway_url = f"{IPFS_GATEWAY}{ipfs_hash}"
        return await self.fetch_metadata(gateway_url, f"IPFS —à–ª—é–∑ ({ipfs_hash})")
    
    async def process_irys_uri(self, uri: str) -> Optional[dict]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å Irys URI —á–µ—Ä–µ–∑ –æ–±–∞ —É–∑–ª–∞"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∏–∑ URI
        if 'irys.xyz' in uri:
            path = uri.split('irys.xyz/')[-1] if 'irys.xyz/' in uri else ''
        else:
            path = uri.split('/')[-1] if '/' in uri else ''
        
        if not path:
            return None
        
        # –ü—Ä–æ–±—É–µ–º –æ–±–∞ —É–∑–ª–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = []
        for i, node in enumerate(IRYS_NODES):
            node_url = f"{node}{path}"
            task = self.fetch_metadata(node_url, f"Irys node{i+1}")
            tasks.append(task)
        
        # –ñ–¥–µ–º –ø–µ—Ä–≤—ã–π —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if isinstance(result, dict):
                print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç Irys node{i+1}")
                return result
        
        return None
    
    async def process_regular_uri(self, uri: str) -> Optional[dict]:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±—ã—á–Ω—ã–π URI"""
        return await self.fetch_metadata(uri, "–æ–±—ã—á–Ω—ã–π URI")
    
    async def process_token(self, token: Token) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω"""
        print(f"\nüîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ç–æ–∫–µ–Ω: {token.name} ({token.symbol})")
        print(f"URI: {token.uri}")
        
        if not token.uri:
            print("‚ùå URI –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            return
        
        metadata = None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø URI –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ
        if self.extract_ipfs_hash(token.uri):
            print("üìÅ –û–±–Ω–∞—Ä—É–∂–µ–Ω IPFS URI, –∏—Å–ø–æ–ª—å–∑—É—é –ø—Ä–∏–≤–∞—Ç–Ω—ã–π —à–ª—é–∑")
            metadata = await self.process_ipfs_uri(token.uri)
        elif self.is_irys_uri(token.uri):
            print("üåê –û–±–Ω–∞—Ä—É–∂–µ–Ω Irys URI, –∏—Å–ø–æ–ª—å–∑—É—é –æ–±–∞ —É–∑–ª–∞")
            metadata = await self.process_irys_uri(token.uri)
        else:
            print("üîó –û–±—ã—á–Ω—ã–π URI, –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å")
            metadata = await self.process_regular_uri(token.uri)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if metadata:
            print(f"üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}")
            # –ò—â–µ–º community_id –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            community_id = self.extract_community_id(metadata)
            if community_id:
                print(f"üèòÔ∏è Community ID: {community_id}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º community_id –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                await self.save_community_id(token, community_id)
            else:
                print("‚ùå Community ID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
        else:
            print("‚ùå –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã (None)")
        
        # –ü–æ–º–µ—á–∞–µ–º —Ç–æ–∫–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
        await self.mark_token_processed(token)
    
    def extract_community_id(self, metadata: dict) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å community_id –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        if not isinstance(metadata, dict):
            return None
        
        def search_in_value(value, path=""):
            """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—Å–∫–∞—Ç—å 'communities' –≤ –∑–Ω–∞—á–µ–Ω–∏–∏"""
            if isinstance(value, str):
                if 'communities' in value.lower():
                    print(f"üîç –ù–∞–π–¥–µ–Ω–æ 'communities' –≤ —Å—Ç—Ä–æ–∫–µ: {value}")
                    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ / –∏ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    parts = value.split('/')
                    if parts:
                        community_id = parts[-1].strip()
                        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
                        community_id = community_id.strip('.,;:!?()[]{}"\'').strip()
                        if community_id and len(community_id) > 0:
                            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω community_id: '{community_id}' –∏–∑ –ø—É—Ç–∏: {path}")
                            return community_id
                        else:
                            print(f"‚ùå Community ID –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: '{parts[-1]}'")
            elif isinstance(value, dict):
                for k, v in value.items():
                    current_path = f"{path}.{k}" if path else k
                    result = search_in_value(v, current_path)
                    if result:
                        return result
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    current_path = f"{path}[{i}]" if path else f"[{i}]"
                    result = search_in_value(item, current_path)
                    if result:
                        return result
            return None
        
        print(f"üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ 'communities' –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        # –ò—â–µ–º –≤–æ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        for key, value in metadata.items():
            result = search_in_value(value, key)
            if result:
                return result
        
        print("‚ùå 'communities' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
        return None
    
    async def save_community_id(self, token: Token, community_id: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å community_id –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            await sync_to_async(Token.objects.filter(id=token.id).update)(
                community_id=community_id
            )
            print(f"üíæ Community ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É: {community_id}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ community_id: {e}")
    
    async def mark_token_processed(self, token: Token) -> None:
        """–ü–æ–º–µ—Ç–∏—Ç—å —Ç–æ–∫–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π"""
        try:
            await sync_to_async(Token.objects.filter(id=token.id).update)(
                twitter_got=True
            )
            print(f"‚úÖ –¢–æ–∫–µ–Ω –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–º–µ—Ç–∫–µ —Ç–æ–∫–µ–Ω–∞: {e}")
    
    async def process_batch(self, batch_size: int = 20):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á —Ç–æ–∫–µ–Ω–æ–≤"""
        print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ –∏–∑ {batch_size} —Ç–æ–∫–µ–Ω–æ–≤...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        tokens = await self.get_tokens_batch(batch_size)
        
        if not tokens:
            print("üì≠ –ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(tokens)} —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
        for i, token in enumerate(tokens, 1):
            print(f"\n--- –¢–æ–∫–µ–Ω {i}/{len(tokens)} ---")
            await self.process_token(token)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏
            if i < len(tokens):
                await asyncio.sleep(0.5)
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤...")
    
    async with TokenProcessor() as processor:
        while True:
            try:
                await processor.process_batch(20)
                print("\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 30 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –±–∞—Ç—á–µ–º...")
                await asyncio.sleep(30)
            except KeyboardInterrupt:
                print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                break
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(10)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
